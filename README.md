# ğŸ’¬ Jai LLM - Resume-based Chatbot

An intelligent chatbot built with RAG (Retrieval Augmented Generation) and Google Gemini API that answers questions about Jai Adithya Nayani's professional experience, skills, and background. This project demonstrates both ML engineering (fine-tuning) and practical AI deployment.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Google Gemini](https://img.shields.io/badge/Google-Gemini-orange.svg)](https://ai.google.dev/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

## ğŸ¯ Project Overview

This project combines two approaches:

1. **Fine-tuning Pipeline** (Showcasing ML Skills)
   - Fine-tune GPT-2 with LoRA on resume data
   - Complete training pipeline with evaluation
   - Demonstrates ML engineering capabilities

2. **RAG Deployment** (Production Chatbot)
   - Semantic search with ChromaDB
   - Google Gemini API for generation
   - Fast, accurate, and easy to update

## âœ¨ Features

- ğŸ¤– **Intelligent Q&A**: Natural conversation about professional background
- ğŸ” **Semantic Search**: RAG-based context retrieval
- ğŸš€ **Fast Responses**: Powered by Google Gemini API
- ğŸ¨ **Beautiful UI**: Modern, responsive web interface
- ğŸ”§ **Easy Updates**: No retraining needed to update information
- ğŸ’» **Local Training**: Fine-tune models on your MacBook
- ğŸ“Š **Model Evaluation**: Comprehensive testing framework

## ğŸ—ï¸ Project Structure

```
jai-llm-chatbot/
â”œâ”€â”€ data/                          # Resume data and processing
â”‚   â”œâ”€â”€ download_resumes.py       # Download PDFs from Google Drive
â”‚   â”œâ”€â”€ process_data.py           # Process and prepare training data
â”‚   â”œâ”€â”€ *.pdf                     # Resume PDFs (gitignored)
â”‚   â”œâ”€â”€ combined_resume.txt       # Processed resume text
â”‚   â””â”€â”€ training_data.jsonl       # Training data for fine-tuning
â”‚
â”œâ”€â”€ fine-tuning/                   # ML training pipeline
â”‚   â”œâ”€â”€ train.py                  # Fine-tune GPT-2 with LoRA
â”‚   â”œâ”€â”€ evaluate.py               # Test the fine-tuned model
â”‚   â””â”€â”€ model_comparison.py       # Compare different approaches
â”‚
â”œâ”€â”€ rag-deployment/                # Production chatbot
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ app.py               # FastAPI server
â”‚   â”‚   â”œâ”€â”€ embeddings.py        # RAG system with ChromaDB
â”‚   â”‚   â””â”€â”€ requirements.txt     # Backend dependencies
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ index.html           # Web interface
â”‚       â”œâ”€â”€ chat.js              # Chat functionality
â”‚       â””â”€â”€ styles.css           # Modern styling
â”‚
â”œâ”€â”€ models/                        # Trained models (gitignored)
â”œâ”€â”€ notebooks/                     # Jupyter notebooks for exploration
â”œâ”€â”€ config.py                      # Configuration
â”œâ”€â”€ requirements.txt               # All dependencies
â””â”€â”€ README.md                      # This file
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.9+
- MacBook with M1/M2 (or any machine with 8GB+ RAM)
- Google Gemini API key (free tier available)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/jai-nayani/jai-llm-chatbot.git
cd jai-llm-chatbot
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Download resume data**
```bash
# Manually download PDFs from Google Drive and place in data/ folder
# Or run the download script:
python data/download_resumes.py
```

5. **Process the data**
```bash
python data/process_data.py
```

6. **Configure API keys**
```bash
# Edit config.py with your Gemini API key
# Or create .env file (recommended)
```

## ğŸ’¡ Usage

### Option 1: RAG Chatbot (Recommended)

**Start the backend:**
```bash
cd rag-deployment/backend
python app.py
```

**Open the frontend:**
```bash
# Open rag-deployment/frontend/index.html in your browser
# Or use a local server:
python -m http.server 8080 --directory rag-deployment/frontend
```

Visit: `http://localhost:8080`

### Option 2: Fine-tuned Model

**Train the model:**
```bash
python fine-tuning/train.py
```

**Test the model:**
```bash
python fine-tuning/evaluate.py
```

## ğŸ”§ Configuration

Edit `config.py` to customize:

```python
# Google Gemini
GEMINI_API_KEY = "your_api_key_here"

# Model settings
TEMPERATURE = 0.7
MAX_TOKENS = 1024

# RAG settings
CHUNK_SIZE = 500
TOP_K_RESULTS = 3

# Fine-tuning settings
LEARNING_RATE = 2e-4
NUM_EPOCHS = 3
```

## ğŸ“Š API Documentation

Once the backend is running, visit:
- Interactive API docs: `http://localhost:8000/docs`
- OpenAPI schema: `http://localhost:8000/openapi.json`

### Endpoints

**POST /chat**
```json
{
  "message": "What are your technical skills?",
  "conversation_history": []
}
```

**Response:**
```json
{
  "response": "I have expertise in...",
  "sources": ["relevant context snippets"]
}
```

## ğŸ¨ Frontend Features

- **Modern UI**: Clean, professional design
- **Quick Questions**: Pre-built queries for common questions
- **Typing Indicators**: Visual feedback during processing
- **Responsive Design**: Works on desktop and mobile
- **Conversation History**: Maintains context across messages

## ğŸ§ª Testing

Test the RAG system:
```bash
python rag-deployment/backend/embeddings.py
```

Test the fine-tuned model:
```bash
python fine-tuning/evaluate.py
```

## ğŸ“ˆ Performance

- **Response Time**: < 2 seconds (with Gemini API)
- **Accuracy**: High relevance with RAG context
- **Cost**: Free tier (15 requests/minute)
- **Scalability**: Easily deployable to cloud platforms

## ğŸš¢ Deployment

### Frontend (GitHub Pages)

1. Push to GitHub
2. Enable GitHub Pages in repository settings
3. Select `rag-deployment/frontend` as source

### Backend Options

**Option A: Google Cloud Run** (Recommended)
```bash
gcloud run deploy jai-llm-api --source .
```

**Option B: Railway**
- Connect GitHub repository
- Set environment variables
- Deploy automatically

**Option C: Vercel (Serverless)**
- Deploy as Vercel Functions
- Set environment variables in dashboard

## ğŸ› ï¸ Technology Stack

- **ML Framework**: PyTorch, Transformers, PEFT (LoRA)
- **LLM**: Google Gemini Pro
- **Vector DB**: ChromaDB
- **Embeddings**: Sentence Transformers
- **Backend**: FastAPI
- **Frontend**: Vanilla JavaScript (no frameworks)
- **Styling**: Modern CSS with animations

## ğŸ“ Example Questions

Try asking:
- "What are your main technical skills?"
- "Tell me about your experience with machine learning"
- "What projects have you worked on?"
- "Which programming languages do you know?"
- "What cloud platforms are you familiar with?"

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Google Gemini for the powerful API
- HuggingFace for transformer models
- FastAPI for the excellent web framework
- ChromaDB for vector storage

## ğŸ“§ Contact

**Jai Adithya Nayani**
- Portfolio: [jai-nayani.github.io](https://jai-nayani.github.io/)
- GitHub: [@jai-nayani](https://github.com/jai-nayani)

---

â­ Star this repo if you find it helpful!

Built with â¤ï¸ and â˜•

